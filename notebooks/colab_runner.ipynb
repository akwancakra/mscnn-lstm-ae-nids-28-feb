{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSCNN-LSTM-AE: Two-Stage Unsupervised NIDS\n",
    "\n",
    "**Stage 1**: Multi-Scale CNN Autoencoder (per-flow spatial features)\n",
    "**Stage 2**: LSTM Autoencoder (temporal patterns on latent sequences)\n",
    "\n",
    "- Train: Benign CIC-IDS-2017 only\n",
    "- Primary eval: CSE-CIC-IDS-2018 (unseen)\n",
    "- Secondary eval: CIC-IDS-2017 all-label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Mount Google Drive & setup\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "PROJECT_ROOT = '/content/drive/MyDrive/mscnn-lstm-ae-nids'\n",
    "os.makedirs(PROJECT_ROOT, exist_ok=True)\n",
    "print(f'Project root: {PROJECT_ROOT}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Install dependencies\n",
    "!pip install -q pyyaml joblib tqdm seaborn scikit-learn scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Copy source code to Colab (upload from local or clone)\n",
    "# Option A: Upload the src/ folder to Google Drive at PROJECT_ROOT/src/\n",
    "# Option B: Clone from git\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "# Verify source files exist\n",
    "src_dir = os.path.join(PROJECT_ROOT, 'src')\n",
    "if os.path.isdir(src_dir):\n",
    "    print('Source directory found')\n",
    "    for root, dirs, files in os.walk(src_dir):\n",
    "        level = root.replace(src_dir, '').count(os.sep)\n",
    "        indent = ' ' * 2 * level\n",
    "        print(f'{indent}{os.path.basename(root)}/')\n",
    "        subindent = ' ' * 2 * (level + 1)\n",
    "        for f in files:\n",
    "            print(f'{subindent}{f}')\n",
    "else:\n",
    "    print(f'ERROR: {src_dir} not found. Upload src/ folder to Google Drive.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Configure dataset paths\n",
    "# Update these paths to match your Google Drive structure\n",
    "CONFIG = {\n",
    "    'runtime': {\n",
    "        'colab_mode': True,\n",
    "        'drive_root': PROJECT_ROOT,\n",
    "        'random_seed': 42,\n",
    "    },\n",
    "    'paths': {\n",
    "        'data_raw_cic': 'data/raw/CIC-IDS2017',\n",
    "        'data_raw_cse': 'data/raw/CSE-CIC-IDS2018',\n",
    "        'data_processed': 'data/processed',\n",
    "        'models_dir': 'models',\n",
    "        'results_dir': 'results',\n",
    "    },\n",
    "    'preprocessing': {\n",
    "        'drop_columns': ['Flow ID'],\n",
    "        'session_columns': {\n",
    "            'src_ip': ['Source IP', 'Src IP'],\n",
    "            'dst_ip': ['Destination IP', 'Dst IP'],\n",
    "            'protocol': ['Protocol'],\n",
    "            'timestamp': ['Timestamp'],\n",
    "        },\n",
    "        'label_candidates': ['Label', 'label', 'Class'],\n",
    "        'benign_label': 'BENIGN',\n",
    "        'scaler': 'robust',\n",
    "        'post_scale_clip': 5.0,\n",
    "        'fillna_strategy': 'median',\n",
    "        'feature_filter': {\n",
    "            'nzv_threshold': 1e-5,\n",
    "            'corr_threshold': 0.98,\n",
    "        },\n",
    "        'chunksize': 50000,\n",
    "    },\n",
    "    'windowing': {\n",
    "        'mode': 'auto',\n",
    "        'window_size': 5,\n",
    "        'min_session_length': 3,\n",
    "        'fallback_mode': 'per_flow',\n",
    "    },\n",
    "    'stage1': {\n",
    "        'latent_dim': 'auto',\n",
    "        'conv_filters': [32, 32, 32],\n",
    "        'conv_kernels': [1, 3, 5],\n",
    "        'reduction_filters': 64,\n",
    "        'batch_size': 256,\n",
    "        'epochs': 100,\n",
    "        'learning_rate': 0.001,\n",
    "        'clipnorm': 1.0,\n",
    "        'early_stopping_patience': 10,\n",
    "        'reduce_lr_patience': 5,\n",
    "        'reduce_lr_factor': 0.5,\n",
    "        'min_lr': 1e-6,\n",
    "    },\n",
    "    'stage2': {\n",
    "        'temporal_latent_dim': 'auto',\n",
    "        'lstm_units': 32,\n",
    "        'dropout': 0.3,\n",
    "        'batch_size': 256,\n",
    "        'epochs': 100,\n",
    "        'learning_rate': 0.001,\n",
    "        'clipnorm': 1.0,\n",
    "        'early_stopping_patience': 10,\n",
    "        'reduce_lr_patience': 5,\n",
    "        'reduce_lr_factor': 0.5,\n",
    "        'min_lr': 1e-6,\n",
    "    },\n",
    "    'scoring': {\n",
    "        'alpha': 0.5,\n",
    "        'alpha_degenerate': 0.7,\n",
    "    },\n",
    "    'threshold': {\n",
    "        'zscore_k': [1.5, 2.0, 2.5, 3.0],\n",
    "        'percentiles': [95, 97, 99, 99.5],\n",
    "        'iqr_k': [1.5, 2.0, 3.0],\n",
    "        'target_fpr': 0.05,\n",
    "    },\n",
    "    'split': {\n",
    "        'val_size': 0.2,\n",
    "        'split_by_file': True,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Verify dataset directories\n",
    "from src.utils import resolve_paths, get_path\n",
    "from src.data.loader import list_csv_files\n",
    "\n",
    "cfg = resolve_paths(CONFIG.copy())\n",
    "\n",
    "cic_dir = get_path(cfg, 'data_raw_cic')\n",
    "cse_dir = get_path(cfg, 'data_raw_cse')\n",
    "\n",
    "print(f'CIC-IDS-2017 dir: {cic_dir}')\n",
    "print(f'CSE-CIC-IDS-2018 dir: {cse_dir}')\n",
    "\n",
    "cic_files = list_csv_files(cic_dir)\n",
    "cse_files = list_csv_files(cse_dir)\n",
    "\n",
    "print(f'\\nCIC CSV files: {len(cic_files)}')\n",
    "for f in cic_files:\n",
    "    print(f'  {f.name}')\n",
    "\n",
    "print(f'\\nCSE CSV files: {len(cse_files)}')\n",
    "for f in cse_files:\n",
    "    print(f'  {f.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Run the full pipeline\n",
    "import logging\n",
    "from src.utils import setup_logging, set_global_seed\n",
    "from src.main import run_pipeline\n",
    "\n",
    "setup_logging('INFO')\n",
    "report = run_pipeline(CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Display results summary\n",
    "import json\n",
    "\n",
    "print('=' * 60)\n",
    "print('RESULTS SUMMARY')\n",
    "print('=' * 60)\n",
    "\n",
    "print(f\"\\nFeatures: {report['n_features_original']} -> {report['n_features_final']}\")\n",
    "print(f\"2D reshape: {report['reshape_2d']}\")\n",
    "print(f\"Latent dim: {report['latent_dim']}\")\n",
    "print(f\"Window size: {report['effective_window_size']}\")\n",
    "\n",
    "print(f\"\\nStage 1 (MSCNN-AE):\")\n",
    "print(f\"  Params: {report['stage1']['total_params']}\")\n",
    "print(f\"  Best val loss: {report['stage1']['best_val_loss']:.6f}\")\n",
    "print(f\"  Epochs: {report['stage1']['n_epochs']}\")\n",
    "\n",
    "print(f\"\\nStage 2 ({report['stage2']['model_type']}):\")\n",
    "print(f\"  Params: {report['stage2']['total_params']}\")\n",
    "print(f\"  Best val loss: {report['stage2']['best_val_loss']:.6f}\")\n",
    "print(f\"  Epochs: {report['stage2']['n_epochs']}\")\n",
    "\n",
    "print(f\"\\nThreshold: {report['thresholds']['selected']} = {report['thresholds']['selected_threshold']:.6f}\")\n",
    "\n",
    "print(f\"\\nCIC-2017:\")\n",
    "cic = report['cic_metrics']\n",
    "print(f\"  ROC-AUC: {cic['roc_auc']:.4f}\")\n",
    "print(f\"  PR-AUC:  {cic['pr_auc']:.4f}\")\n",
    "print(f\"  F1:      {cic['f1']:.4f}\")\n",
    "print(f\"  FPR:     {cic['fpr']:.4f}\")\n",
    "\n",
    "print(f\"\\nCSE-2018 (PRIMARY):\")\n",
    "cse = report['cse_metrics']\n",
    "print(f\"  ROC-AUC: {cse['roc_auc']:.4f}\")\n",
    "print(f\"  PR-AUC:  {cse['pr_auc']:.4f}\")\n",
    "print(f\"  F1:      {cse['f1']:.4f}\")\n",
    "print(f\"  FPR:     {cse['fpr']:.4f}\")\n",
    "\n",
    "print(f\"\\nGeneralization: {report['generalization']['verdict']}\")\n",
    "print(f\"  AUC drop: {report['generalization']['auc_drop']:.4f}\")\n",
    "print(f\"  F1 drop:  {report['generalization']['f1_drop']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Display generated plots\n",
    "from IPython.display import Image, display\n",
    "from pathlib import Path\n",
    "\n",
    "results_path = get_path(cfg, 'results_dir')\n",
    "\n",
    "plots = [\n",
    "    'stage1_training_curves.png',\n",
    "    'stage2_training_curves.png',\n",
    "    'domain_shift.png',\n",
    "    'session_lengths.png',\n",
    "    'roc_curves_combined.png',\n",
    "    'pr_curves_combined.png',\n",
    "    'cic2017_error_dist.png',\n",
    "    'cse2018_error_dist.png',\n",
    "    'cic2017_cm.png',\n",
    "    'cse2018_cm.png',\n",
    "    'cic2017_dr.png',\n",
    "    'cse2018_dr.png',\n",
    "    'cic2017_violin.png',\n",
    "    'cse2018_violin.png',\n",
    "    'threshold_comparison.png',\n",
    "]\n",
    "\n",
    "for p in plots:\n",
    "    fp = results_path / p\n",
    "    if fp.exists():\n",
    "        print(f'\\n--- {p} ---')\n",
    "        display(Image(filename=str(fp), width=700))\n",
    "    else:\n",
    "        print(f'  [not found] {p}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Per-attack detection rates\n",
    "import pandas as pd\n",
    "\n",
    "for ds in ['cic2017', 'cse2018']:\n",
    "    dr_path = results_path / f'{ds}_detection_rates.csv'\n",
    "    if dr_path.exists():\n",
    "        print(f'\\n{ds.upper()} Detection Rates:')\n",
    "        dr = pd.read_csv(dr_path)\n",
    "        display(dr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Domain shift details\n",
    "shift_path = results_path / 'domain_shift_features.csv'\n",
    "if shift_path.exists():\n",
    "    shift_df = pd.read_csv(shift_path)\n",
    "    print('Top 15 features with highest domain shift:')\n",
    "    display(shift_df.head(15))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
